import { HuggingFaceEmbedding } from '@llamaindex/huggingface';
import { SimpleDirectoryReader } from '@llamaindex/readers/directory';
import {
  Settings,
  VectorStoreIndex,
  storageContextFromDefaults,
} from 'llamaindex';
import * as path from 'path';
import { config } from 'dotenv';

config();

process.env.TRANSFORMERS_BACKEND = 'onnxruntime-node';

async function main() {
  console.log('üöÄ Starting data ingestion...');

  Settings.embedModel = new HuggingFaceEmbedding({
    modelType: 'BAAI/bge-small-en-v1.5',
  });
  console.log('‚ú® Embedding model set to HuggingFace (BAAI/bge-small-en-v1.5)');

  const dataDir = path.resolve(__dirname, 'data');
  const persistDir = path.resolve(__dirname, 'storage');

  const reader = new SimpleDirectoryReader();
  const documents = await reader.loadData(dataDir);
  console.log(`‚úÖ Loaded ${documents.length} document(s).`);

  const storageContext = await storageContextFromDefaults({ persistDir });
  console.log('‚öôÔ∏è Creating index and embeddings...');

  await VectorStoreIndex.fromDocuments(documents, { storageContext });
  console.log("‚úÖ Ingestion complete. Index saved in './storage'.");
}
main().catch(console.error);
